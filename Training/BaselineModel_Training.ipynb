{"cells":[{"cell_type":"code","execution_count":1,"id":"9ee57490","metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["23/12/02 22:36:24 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+----------+------------------+------------------+--------------+-----------+--------+--------+--------+-------------------+\n","|is_helpful|          scoreVec|sum_compound_score|summary_length|text_length|text_neg|text_neu|text_pos|weekdayOrWeekendVec|\n","+----------+------------------+------------------+--------------+-----------+--------+--------+--------+-------------------+\n","|         0|    {[], 5, 0, []}|               0.0|            29|        854|   0.259|   0.664|   0.077| {[0], 1, 0, [1.0]}|\n","|         0|{[1], 5, 0, [1.0]}|               0.0|            23|        312|   0.283|   0.681|   0.036| {[0], 1, 0, [1.0]}|\n","|         1|    {[], 5, 0, []}|               0.0|            29|       1709|   0.017|   0.876|   0.107|     {[], 1, 0, []}|\n","|         1|    {[], 5, 0, []}|               0.0|            54|       1072|   0.005|   0.796|   0.199| {[0], 1, 0, [1.0]}|\n","|         1|    {[], 5, 0, []}|            0.3612|            42|        725|   0.018|   0.858|   0.124| {[0], 1, 0, [1.0]}|\n","|         1|{[4], 5, 0, [1.0]}|               0.0|            16|       1447|   0.013|   0.791|   0.196| {[0], 1, 0, [1.0]}|\n","|         1|    {[], 5, 0, []}|            0.6249|            23|        675|   0.014|   0.734|   0.253| {[0], 1, 0, [1.0]}|\n","|         1|    {[], 5, 0, []}|            0.8439|            26|        309|     0.0|   0.838|   0.162| {[0], 1, 0, [1.0]}|\n","|         1|    {[], 5, 0, []}|               0.0|            31|        259|     0.0|   0.684|   0.316| {[0], 1, 0, [1.0]}|\n","|         1|    {[], 5, 0, []}|              0.34|            43|        700|   0.127|   0.643|    0.23|     {[], 1, 0, []}|\n","|         1|    {[], 5, 0, []}|               0.0|            40|       1793|   0.114|   0.715|   0.171|     {[], 1, 0, []}|\n","|         1|    {[], 5, 0, []}|             0.765|            29|        681|   0.023|   0.865|   0.112|     {[], 1, 0, []}|\n","|         1|    {[], 5, 0, []}|               0.0|            35|       1083|   0.032|   0.808|    0.16|     {[], 1, 0, []}|\n","|         1|    {[], 5, 0, []}|           -0.5267|            32|       4388|   0.084|   0.746|    0.17|     {[], 1, 0, []}|\n","|         1|    {[], 5, 0, []}|             0.872|            46|       1183|   0.064|   0.704|   0.232| {[0], 1, 0, [1.0]}|\n","|         1|{[4], 5, 0, [1.0]}|            0.5927|            39|       4858|    0.09|   0.794|   0.116| {[0], 1, 0, [1.0]}|\n","|         1|{[4], 5, 0, [1.0]}|            0.5574|            21|       4514|   0.107|   0.709|   0.184| {[0], 1, 0, [1.0]}|\n","|         1|{[4], 5, 0, [1.0]}|           -0.5267|            29|       1341|   0.107|   0.686|   0.207| {[0], 1, 0, [1.0]}|\n","|         1|{[4], 5, 0, [1.0]}|            0.1531|            52|       2059|   0.071|   0.734|   0.195|     {[], 1, 0, []}|\n","|         1|{[3], 5, 0, [1.0]}|            0.1451|            36|       1201|   0.008|   0.796|   0.196| {[0], 1, 0, [1.0]}|\n","+----------+------------------+------------------+--------------+-----------+--------+--------+--------+-------------------+\n","only showing top 20 rows\n","\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder \\\n","        .appName(\"Json to DataFrame\") \\\n","        .getOrCreate()\n","\n","df = spark.read.json(\"gs://dataproc-staging-us-east1-766635705898-g9ye7adw/final_project/data_feature.json_part-00000-81821db2-daa5-40c6-8ebe-5eaa98c07e5c-c000.json\")\n","df.show()"]},{"cell_type":"code","execution_count":2,"id":"57928b39","metadata":{},"outputs":[{"data":{"text/plain":["StructType([StructField('is_helpful', LongType(), True), StructField('scoreVec', StructType([StructField('indices', ArrayType(LongType(), True), True), StructField('size', LongType(), True), StructField('type', LongType(), True), StructField('values', ArrayType(DoubleType(), True), True)]), True), StructField('sum_compound_score', DoubleType(), True), StructField('summary_length', LongType(), True), StructField('text_length', LongType(), True), StructField('text_neg', DoubleType(), True), StructField('text_neu', DoubleType(), True), StructField('text_pos', DoubleType(), True), StructField('weekdayOrWeekendVec', StructType([StructField('indices', ArrayType(LongType(), True), True), StructField('size', LongType(), True), StructField('type', LongType(), True), StructField('values', ArrayType(DoubleType(), True), True)]), True)])"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df.schema"]},{"cell_type":"code","execution_count":3,"id":"e6da993a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.linalg import Vectors\n","\n","# List of input columns for features (excluding the target variable and nested columns)\n","input_cols = ['sum_compound_score', 'summary_length', 'text_length', 'text_neg', 'text_neu', 'text_pos']\n","\n","# Assemble the features into a single feature vector\n","assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n","df = assembler.transform(df)\n","\n","# Select only the features and the target column\n","df = df.select(\"features\", df.is_helpful.alias(\"label\"))\n","train_data, test_data = df.randomSplit([0.75, 0.25], seed=42)\n","from pyspark.ml.classification import LogisticRegression\n","\n","# Initialize the Logistic Regression model\n","lr = LogisticRegression()\n","\n","# Train the model\n","model = lr.fit(train_data)\n"]},{"cell_type":"code","execution_count":4,"id":"ba2a787e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Test Area Under ROC: 0.7001703367078497\n","Test Accuracy: 0.6862546437014522\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","\n","# Make predictions on the test data\n","predictions = model.transform(test_data)\n","\n","# Initialize the evaluator\n","evaluator = BinaryClassificationEvaluator()\n","\n","# Evaluate the model\n","accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})\n","\n","print(f\"Test Area Under ROC: {accuracy}\")\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","# Use the MulticlassClassificationEvaluator to evaluate the model\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","\n","# Calculate accuracy on the test data\n","accuracy = evaluator.evaluate(predictions)\n","\n","print(f\"Test Accuracy: {accuracy}\")\n"]},{"cell_type":"code","execution_count":5,"id":"11f68ee2","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.70145221209051\n","Test Area Under ROC: 0.7231770185453665\n"]}],"source":["from pyspark.ml.classification import RandomForestClassifier\n","\n","# Initialize the Random Forest model\n","rf = RandomForestClassifier()\n","\n","# Train the model on the training data\n","rf_model = rf.fit(train_data)\n","\n","# Make predictions on the test data\n","rf_predictions = rf_model.transform(test_data)\n","\n","# Evaluate the model using MulticlassClassificationEvaluator for accuracy\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(rf_predictions)\n","print(f\"Test Accuracy: {accuracy}\")\n","\n","# Evaluate the model using BinaryClassificationEvaluator for area under ROC\n","binary_evaluator = BinaryClassificationEvaluator()\n","roc_auc = binary_evaluator.evaluate(rf_predictions, {binary_evaluator.metricName: \"areaUnderROC\"})\n","print(f\"Test Area Under ROC: {roc_auc}\")\n"]},{"cell_type":"code","execution_count":10,"id":"93545e8b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sparkxgb\n","  Downloading sparkxgb-0.1.tar.gz (3.6 kB)\n","  Preparing metadata (setup.py) ... \u001B[?25ldone\n","\u001B[?25hCollecting pyspark==3.1.1 (from sparkxgb)\n","  Downloading pyspark-3.1.1.tar.gz (212.3 MB)\n","\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m212.3/212.3 MB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n","\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\n","\u001B[?25hCollecting py4j==0.10.9 (from pyspark==3.1.1->sparkxgb)\n","  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n","\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m198.6/198.6 kB\u001B[0m \u001B[31m25.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n","\u001B[?25hBuilding wheels for collected packages: sparkxgb, pyspark\n","  Building wheel for sparkxgb (setup.py) ... \u001B[?25ldone\n","\u001B[?25h  Created wheel for sparkxgb: filename=sparkxgb-0.1-py3-none-any.whl size=5627 sha256=43dd086c594fd4c4c08fdeec8f566084dc472d27c6e293959ea5c31e1d7b696c\n","  Stored in directory: /root/.cache/pip/wheels/b7/0c/a1/786408e13056fabeb8a72134e101b1e142fc95905c7b0e2a71\n","  Building wheel for pyspark (setup.py) ... \u001B[?25ldone\n","\u001B[?25h  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767582 sha256=9e1c95ef2d5a52d5858cf366a934f9110e643693d17885b3639daba306b0ac1e\n","  Stored in directory: /root/.cache/pip/wheels/a0/3f/72/8efd988f9ae041f051c75e6834cd92dd6d13a726e206e8b6f3\n","Successfully built sparkxgb pyspark\n","Installing collected packages: py4j, pyspark, sparkxgb\n","  Attempting uninstall: py4j\n","    Found existing installation: py4j 0.10.9.5\n","    Uninstalling py4j-0.10.9.5:\n","      Successfully uninstalled py4j-0.10.9.5\n","  Attempting uninstall: pyspark\n","    Found existing installation: pyspark 3.3.2\n","    Uninstalling pyspark-3.3.2:\n","      Successfully uninstalled pyspark-3.3.2\n","Successfully installed py4j-0.10.9 pyspark-3.1.1 sparkxgb-0.1\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install sparkxgb"]},{"cell_type":"code","execution_count":7,"id":"0f46e212","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.6786555942094041\n"]}],"source":["from pyspark.ml.classification import LinearSVC\n","\n","# Initialize the LinearSVC model\n","svm = LinearSVC()\n","\n","# Train the model on the training data\n","svm_model = svm.fit(train_data)\n","# Make predictions on the test data\n","svm_predictions = svm_model.transform(test_data)\n","\n","# Evaluate the model using MulticlassClassificationEvaluator for accuracy\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(svm_predictions)\n","print(f\"Test Accuracy: {accuracy}\")\n"]},{"cell_type":"code","execution_count":null,"id":"d311bff3","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}
